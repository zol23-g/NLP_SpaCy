{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Natural Language Processing (NLP) Assignment\n", "This assignment will guide you through the basic concepts of Natural Language Processing including:\n", "- Text preprocessing\n", "- Tokenization and N-grams\n", "- Named Entity Recognition (NER)\n", "- Converting text into numbers (vectorization)\n", "- Word embeddings (for experienced learners)\n", "\n", "You can run and modify the code cells below to complete the tasks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import required libraries\n", "import nltk\n", "import spacy\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "import matplotlib.pyplot as plt\n", "from wordcloud import WordCloud\n", "import numpy as np\n", "import pandas as pd\n", "nltk.download('punkt')\n", "nltk.download('averaged_perceptron_tagger')\n", "nltk.download('maxent_ne_chunker')\n", "nltk.download('words')\n", "nltk.download('stopwords')\n", "from nltk.corpus import stopwords\n", "from nltk.tokenize import word_tokenize\n", "from nltk import ngrams\n", "nlp = spacy.load(\"en_core_web_sm\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Text Preprocessing\n", "Clean the following text by converting it to lowercase, removing punctuation and stop words."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample text\n", "text = \"Natural Language Processing is a fascinating field. It combines linguistics and computer science!\"\n", "\n", "# TODO: Preprocess the text\n", "def preprocess(text):\n", "    # Convert to lowercase\n", "    # Tokenize\n", "    # Remove punctuation and stopwords\n", "    return cleaned_tokens\n", "\n", "# Print cleaned tokens\n", "cleaned_tokens = preprocess(text)\n", "print(cleaned_tokens)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Tokenization and N-grams\n", "Generate bigrams (2-grams) from the cleaned tokens."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Generate bigrams from cleaned tokens\n", "bigrams = list(ngrams(cleaned_tokens, 2))\n", "print(\"Bigrams:\", bigrams)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Named Entity Recognition (NER)\n", "Use spaCy to perform NER on a new sentence."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Example sentence\n", "sentence = \"Barack Obama was born in Hawaii and was elected president in 2008.\"\n", "doc = nlp(sentence)\n", "for ent in doc.ents:\n", "    print(ent.text, ent.label_)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Converting Text to Numbers\n", "Use CountVectorizer and TfidfVectorizer to convert a list of sentences into numeric vectors."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sentences = [\n", "    \"I love machine learning.\",\n", "    \"Natural language processing is a part of AI.\",\n", "    \"AI is the future.\"\n", "]\n", "\n", "# CountVectorizer\n", "count_vec = CountVectorizer()\n", "X_count = count_vec.fit_transform(sentences)\n", "print(\"Count Vectorizer Output:\\n\", X_count.toarray())\n", "\n", "# TfidfVectorizer\n", "tfidf_vec = TfidfVectorizer()\n", "X_tfidf = tfidf_vec.fit_transform(sentences)\n", "print(\"\\nTF-IDF Vectorizer Output:\\n\", X_tfidf.toarray())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Word Embeddings (Advanced)\n", "Use spaCy to get word vectors (embeddings) for given words."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Note: en_core_web_sm does not have word vectors. You can install and use en_core_web_md\n", "# Uncomment below to install and load the medium model if needed.\n", "# !python -m spacy download en_core_web_md\n", "# nlp = spacy.load(\"en_core_web_md\")\n", "\n", "# Example word vector\n", "word = nlp(\"machine\")[0]\n", "print(\"Vector for 'machine':\\n\", word.vector)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}